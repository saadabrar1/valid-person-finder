# üîç Person Finder Tool

An AI-powered intelligence tool that finds key personnel at any company by designation. It cross-validates results across multiple search engines and uses LLM-based extraction for high-confidence, structured output.

## Workflow

![Person Finder Workflow](workflow.png)

## How It Works

1. **User inputs** a company name and designation (e.g. *Microsoft*, *CEO*)
2. **Researcher Agent** generates smart queries (with alias expansion like CEO ‚Üí Chief Executive Officer), searches both SerpAPI and DuckDuckGo, and merges/deduplicates results
3. **Validator Agent** scrapes page content, extracts candidate names via regex + Groq LLM, cross-validates across engines, and scores source credibility
4. **Reporter Agent** selects the best candidate, calculates a composite confidence score, and returns structured JSON
5. If confidence < 0.5, the pipeline **automatically retries** with refined queries (max 1 retry)

## Tech Stack

| Layer | Technology |
|-------|-----------|
| UI | Streamlit |
| Orchestration | LangChain + LangGraph |
| LLM | Groq (llama-3.1-8b-instant) |
| Primary Search | SerpAPI (Google) |
| Fallback Search | DuckDuckGo |
| Scraping | requests, BeautifulSoup, Selenium, readability-lxml |
| Logging | Python logging ‚Üí `logs/app.log` |

## Project Structure

```
‚îú‚îÄ‚îÄ streamlit_app.py          # Streamlit UI
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # Entry point ‚Äî find_person()
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ researcher.py     # Query generation + search
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validator.py      # Extraction + cross-validation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reporter.py       # Scoring + JSON output
‚îÇ   ‚îú‚îÄ‚îÄ graph/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py          # LangGraph TypedDict state
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ builder.py        # Workflow graph with retry logic
‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_tools.py   # SerpAPI + DuckDuckGo wrappers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraper.py        # ContentScraper (requests/Selenium)
‚îÇ   ‚îî‚îÄ‚îÄ utilis/
‚îÇ       ‚îî‚îÄ‚îÄ logger.py         # Logging config
‚îú‚îÄ‚îÄ logs/                     # Runtime logs
‚îú‚îÄ‚îÄ .env                      # API keys (not committed)
‚îî‚îÄ‚îÄ requirements.txt
```

## Setup

```bash
# 1. Clone the repo
git clone <repo-url> && cd valid-person-finder

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment variables
# Create a .env file in the root with:
GROQ_API_KEY=your_groq_api_key
SERPAPI_API_KEY=your_serpapi_key

# 4. Run
streamlit run streamlit_app.py
```

## Output Format

```json
{
  "first_name": "Satya",
  "last_name": "Nadella",
  "current_title": "CEO",
  "company": "Microsoft",
  "source_url": "https://...",
  "confidence_score": 0.92
}
```

**Confidence formula:**
`(source_credibility √ó 0.5) + (cross_engine_validation √ó 0.3) + (designation_match √ó 0.2)`

## License

MIT